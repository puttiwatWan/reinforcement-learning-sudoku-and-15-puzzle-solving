{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement Learning Project - Sirichai and Puttiwat.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ck5_TuPAe7B1",
        "UH1TlY9ZSEPK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rakSaeH0Gm2m",
        "colab_type": "text"
      },
      "source": [
        "# Reinforcement Learning Project\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<H2>Case Study for Using Reinforcement Learning Technique in Sudoku Game and 15-Puzzle Game </H2>\n",
        "<br>Reinforcement Learning  (TX00DQ05-3001)\n",
        "<br>Instructor: Peter Hjort (Peter.Hjort@metropolia.fi)\n",
        "<br>Department of Information Technology\n",
        "<br>Metropolia University of Appiled Sciences, Helsinki, Finland\n",
        "<br>\n",
        "<br>Members:\n",
        "<br>1900553 Sirichai Khomleart (sirichai.khomleart@gmail.com)\n",
        "<br>1900554 Puttiwat Wanna (puttiwat.wan@gmail.com)\n",
        "<br>\n",
        "<br>Last edited: May 7, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of53-rJ0ITJe",
        "colab_type": "text"
      },
      "source": [
        "## 0. Table of Contents\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. Introduction to the Case Study\n",
        "2. Importing Nescessary Libraries\n",
        "3. Sudoku Game\n",
        "        3.1. General Information about Sudoku Game\n",
        "        3.2. Brute Force Algorithm\n",
        "        3.3. Reinforcement Algorithm (Temporal Difference Control: Sarsa)\n",
        "            3.3.1. State\n",
        "            3.3.2. Action\n",
        "            3.3.3. Reward\n",
        "            3.3.4. Algorithm\n",
        "            3.3.5. Take a step further\n",
        "4. 15-Puzzle Game\n",
        "        4.1. General Information about 15-Puzzle Game\n",
        "        4.2. Brute Force Algorithm\n",
        "        4.3. Reinforcement Algorithm (Temporal Difference Control: Sarsa)\n",
        "            4.3.1. State\n",
        "            4.3.2. Action\n",
        "            4.3.3. Reward\n",
        "            4.3.4. Algorithm\n",
        "5. Conclusion\n",
        "6. References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aodWJvWJpL_",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction to the Case Study\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This case study is a part of Reinforcement Learning course (TX00DQ05-3001), Metropolia University of Applied Sciences, Finland. The objective of this case study is to try applying reinforcement learning techniques to the puzzle games, like sudoku and 15-puzzle. \n",
        "<br>\n",
        "<br>Normally, puzzle games, such as sudoku and 15-puzzle, can be solve by hands using guess-and-try technique. People try to find the solution by applying a possible choice of actions to the problem to see whether the selected choice is correct or not. If the selected choice is correct, then continue to solve the remaining problems until all the puzzles are solved. If not, then go back to the last state before selecting an action, then try another action hoping that the new action is the right one that leads to the solution. This process will go over and over again as we solve the puzzle. During this process, the knowledge about the puzzle will be gained so that it can be used to solve other similar puzzles in the future.\n",
        "<br>\n",
        "<br>To use computer programming to solve these puzzle games, the brute force technique was used to find the right solution from all possible actions in the puzzle. Brute force algorithm will guarantee that the outcome will absolutely be found, if that puzzle is valid or solveable. This brute force technique will do the depth first search, generate all possible actions and solutions to see which one is the correct solution for specific puzzle, then output as an answer to that puzzle. \n",
        "<br>\n",
        "<br>However, as the algorithm will try to find possible outputs form all possible actions, this bruce force technique likely to take very long time to solve a puzzle. So, an idea to use reinforment learning techniques learned in the class was used to apply to these problems, to let an agent learns about the puzzles and find the policy that leads itself to the correct answer. This way, the agent will have some knowledge and idea of which action should be taken in different states of the puzzle. When the new puzzle comes, the agent can use those knowledge gained from the past puzzles to take an action without learning again about that new puzzle from the start like the brute force algorithm.\n",
        "<br>\n",
        "<br>As stated earlier, this case study will use sudoku game and 15-puzzle game as the puzzles to experiment with, since the general concepts of these two puzzle are easy to understand and the states and actions for the agent are easy to define.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVIuVL-UhRTJ",
        "colab_type": "text"
      },
      "source": [
        "## 2. Importing Nescessary Libraries\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_SNkR0Dg7p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import copy\n",
        "import operator\n",
        "import numpy as np\n",
        "from numpy import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNC9pxKq8faN",
        "colab_type": "text"
      },
      "source": [
        "The library **copy** is used to copy an array-like object from one variable to another variable. Normally, it should be just \"**ListB = ListA**\" when copying the list. However, this case study was done on Google Colaboratory and the problem is that if it is assigned the normal way (**ListB = ListA**), the program will use the same memory location for both **ListB** and **ListA** since it just copies the location of **ListA** to **ListB**. As a result, if any changes occur in **ListB**, it will also occur in **ListA** since they are considered the same variable (use the same memory location)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9k7EqFFJxYA",
        "colab_type": "text"
      },
      "source": [
        "## 3. Sudoku Game\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ex26WtjTmjY",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 General Information about Sudoku Game\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sudoku is the popular Japanese puzzle game based on the logical placement of numbers. The goal of Sudoku is to fill in a 9×9 grid with digits so that each column, row, and 3×3 section contains all numbers from 1 to 9. At the beginning of the game, the 9×9 grid will have some of the squares filled in. The player’s job is to fill in missing digits and complete the grid.<br>\n",
        "<br>\n",
        "To sum it up, the player has to fill the numbers between 1 to 9 into each blank square until the whole grid is filled. The condition for the complete grid to be the correct answer is that when looking at all points of view (row, column, or 3x3 section), all numbers from 1 to 9 has to be present. For an example, there cannot be any same number in each row, column, or the 3x3 section.<br>\n",
        "<br>\n",
        "The figure below shows an example of the sudoku puzzle. The left image is the problems given at the beginning and the right image is the solved one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mcOmLykUJF6",
        "colab_type": "text"
      },
      "source": [
        "<img src='data:image/png;base64,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' width=250> <img src='https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Sudoku_Puzzle_by_L2G-20050714_solution_standardized_layout.svg/250px-Sudoku_Puzzle_by_L2G-20050714_solution_standardized_layout.svg.png' width=250>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCHH-tjvCS-x",
        "colab_type": "text"
      },
      "source": [
        "The sudoku puzzle may be in any forms of an *N x N* grid and there will be N subregions (the 3x3 sections in 9x9 grid) with the size of $\\sqrt{N}$x$\\sqrt{N}$, where N is the squared of 2, 3, 4, and so on. However, normally, it will be in the form of 9x9. The numbers available to be filled are 1 to *N*. For example, if *N = 4*, it will be a 4x4 grid with 4 subregions having the size of 2x2 each and the numbers needed to be present in each row, column, and subregions are 1 to 4. <br>\n",
        "<br>\n",
        "There may also be other types of sudoku puzzle but in this case study, only the original type (*N x N* with *N* subregions, each with a size of $\\sqrt{N}$x$\\sqrt{N}$) will be taken into account. Here are some examples of the other types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5GhZl1vDphO",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://mathpuzzle.com/Sudoku/WeiHwaSudoku/22-wacky-geometric.gif\" width=500>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV5eqahEWp3d",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Brute Force Algorithm\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "From 81 squares available in Sudoku games, each square can be any number from 1 to 9, so there are 6,670,903,752,021,072,936,960 possible solutions of sudoku. Using the normal brute force technique that builds a tree and does the depth first search can take very long time. Therefore, instead of trying all possible solutions, the impossible actions that make sudoku invalid will be eliminated while exploring the tree in depth-first search algorithm. This technique is also known as bracktracking. \n",
        "<br>\n",
        "<br>The idea of backtracking search is a normal depth-first search that will completely explore one branch to a possible solution before moving to another branch. This is one of the most general and basic techniques for searching for possible solutions of a problem as every possible moves are generated and is then tested to see whether it solves the problem. Although it has been established that approximately 6.67 x $10^{21}$ final grids exist, a brute force algorithm can be a practical method to solve Sudoku puzzles.\n",
        "<br>\n",
        "<br>A brute force algorithm visits the empty cells in some order, filling in digits sequentially, or backtracking when the number is found to be not valid. Briefly, a program would solve a puzzle by placing the digit \"1\" in the first cell and checking if it is allowed to be there. If there are no violations (checking row, column, and box (or subregion) constraints) then the algorithm advances to the next cell, and places a \"1\" in that cell. When checking for violations, if it discovers that the \"1\" is not allowed, the value is advanced to \"2\". If a cell discovers where none of the 9 digits is allowed, then the algorithm leaves that cell blank and moves back to the previous cell. The value in that cell is then incremented by one. This is repeated until the allowed value in the last (81st) cell is discovered. [1]\n",
        "<br>\n",
        "<br>The animation below shows how a Sudoku is solved with this method. The puzzle's clues (initial numbers) shown in red remain fixed while the algorithm tests each unsolved cell with a possible solution. Notice that the algorithm may discard all the previously tested values if it finds the existing set does not fulfil the constraints of the Sudoku. [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUGb26WmW_qF",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://upload.wikimedia.org/wikipedia/commons/8/8c/Sudoku_solved_by_bactracking.gif' width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivxty-TQb-LD",
        "colab_type": "text"
      },
      "source": [
        "To have more idea how backtracking algorithm work, here are the code and explanation of the backtracking algorithm.\n",
        "<br>\n",
        "<br>First, we designed the sudoku puzzle into 2D array list called container. The blank space in the sudoku puzzle will be replaced as number 0 in the list. The goal of solving puzzle is to find a valid sudoku without number 0 remaining in the list (all blank space filled). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnUsrrHXQRfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "container9 = [\n",
        "            [5, 3, 0, 0, 7, 0, 0, 0, 0],\n",
        "            [6, 0, 0, 1, 9, 5, 0, 0, 0],\n",
        "            [0, 9, 8, 0, 0, 0, 0, 6, 0],\n",
        "            [8, 0, 0, 0, 6, 0, 0, 0, 3],\n",
        "            [4, 0, 0, 8, 0, 3, 0, 0, 1],\n",
        "            [7, 0, 0, 0, 2, 0, 0, 0, 6],\n",
        "            [0, 6, 0, 0, 0, 0, 2, 8, 0],\n",
        "            [0, 0, 0, 4, 1, 9, 0, 0, 5],\n",
        "            [0, 0, 0, 0, 8, 0, 0, 7, 9]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSrG7RArci-T",
        "colab_type": "text"
      },
      "source": [
        "Then create a function to check the validity of the sudoku. The valid sudoku means that each row, column, and small 3x3 box have no repeated numbers in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aQMMruRcWQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_filled(puzzle):\n",
        "    # Check if the puzzle is entirely filled.\n",
        "    for row in puzzle:\n",
        "        if 0 in row: return False\n",
        "    return True\n",
        "\n",
        "def check_square(num, row, col, puzzle):\n",
        "    # Check if num is valid at puzzle[row][col] based on the 3x3 box it resides in\n",
        "    yPos = row % 3\n",
        "    xPos = col % 3\n",
        "\n",
        "    if yPos == 0:\n",
        "        yRange = range(row, row+3)\n",
        "    elif yPos == 1:\n",
        "        yRange = range(row-1, row+2)\n",
        "    elif yPos == 2:\n",
        "        yRange = range(row-2, row+1)\n",
        "\n",
        "    if xPos == 0:\n",
        "        xRange = range(col, col+3)\n",
        "    elif xPos == 1:\n",
        "        xRange = range(col-1, col+2)\n",
        "    elif xPos == 2:\n",
        "        xRange = range(col-2, col+1)\n",
        "\n",
        "    for i in yRange:\n",
        "        for j in xRange:\n",
        "            if puzzle[i][j] == num:\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "def check_row_col(num, row, col, puzzle):\n",
        "    # Check if column and row  are valid\n",
        "    for j in range(9):\n",
        "        if puzzle[row][j] == num or puzzle[j][col] == num:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_position_valid(num, row, col, puzzle):\n",
        "    return (check_square(num, row, col, puzzle)\n",
        "            and check_row_col(num, row, col, puzzle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0F-ws-KeK-1",
        "colab_type": "text"
      },
      "source": [
        "After that, define a function to find the number 0 (blank space) in the list to let the algorithm try to fill the numbers later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY_QGd2ZeKnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def first_unused(puzzle):\n",
        "    # Returns the [row, col] of the topmost-leftmost 0 in puzzle\n",
        "    for i, row in enumerate(puzzle):\n",
        "        if 0 in row:\n",
        "            zeroAt = row.index(0)\n",
        "            return [i, zeroAt]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxgu2TVevlM",
        "colab_type": "text"
      },
      "source": [
        "Next, define a function to replace number zero with some possible number that still makes the puzzle valid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH8fYFZWe3aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_number(puzzle):\n",
        "    # Returns a list of puzzles with the firstUnused(puzzle) replaced with 1 <= i <= 9, if i is valid in that position\n",
        "    unused = first_unused(puzzle)\n",
        "    row = unused[0]\n",
        "    col = unused[1]\n",
        "    res = []\n",
        "    for i in range(1, 10):\n",
        "        if not is_position_valid(i, row, col, puzzle): continue\n",
        "        r = [puzzle[j][:] for j in range(len(puzzle))]\n",
        "        r[row][col] = i\n",
        "        res.append(r)\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_gR-JCVfEHt",
        "colab_type": "text"
      },
      "source": [
        "Finally, define functions for solving sudoku."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOwfKiA-fDny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def solve_list(puzzles):\n",
        "    # Produces the solution for one of the puzzles or False\n",
        "    if puzzles == []:\n",
        "        return False\n",
        "    else:\n",
        "        cur = solve(puzzles[0])\n",
        "        if not cur:\n",
        "            if puzzles == []:\n",
        "                return False\n",
        "            else: return solve_list(puzzles[1:])\n",
        "        return cur\n",
        "\n",
        "def solve(puzzle):\n",
        "    # Produces the solved puzzle or return False in case of no valid solution available\n",
        "    if is_filled(puzzle):\n",
        "        return puzzle\n",
        "    else: return solve_list(add_number(puzzle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB6E2jVbilVl",
        "colab_type": "text"
      },
      "source": [
        "To have a beatiful output,  the print function is also defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtEnyME9ikJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_sudoku(container):\n",
        "  boxLength = int(math.sqrt(len(container)))\n",
        "  print(\"\",\"-\"*((boxLength*2+2)*boxLength+1))\n",
        "  for r in range(len(container)):   \n",
        "    storage = \"\"\n",
        "    for c in range(len(container)):\n",
        "      if (c)%boxLength == 0:\n",
        "        storage+=\" |\"\n",
        "      storage+=\" \"+str(container[r][c])\n",
        "    storage+=\" |\"\n",
        "    print(storage)\n",
        "    if (r+1)%boxLength == 0:\n",
        "      print(\"\",\"-\"*((boxLength*2+2)*boxLength+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmxYNP6Ocb6H",
        "colab_type": "code",
        "outputId": "0228f3b2-db0f-4632-8477-6cfb074c9023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "print(\"Question Puzzle: \")\n",
        "print_sudoku(container9)\n",
        "print(\"Answer: \")\n",
        "start_time = time.time()\n",
        "print_sudoku(solve(container9))\n",
        "end_time = time.time()\n",
        "print(\"Time used:\",end_time - start_time,\"seconds\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question Puzzle: \n",
            " -------------------------\n",
            " | 5 3 0 | 0 7 0 | 0 0 0 |\n",
            " | 6 0 0 | 1 9 5 | 0 0 0 |\n",
            " | 0 9 8 | 0 0 0 | 0 6 0 |\n",
            " -------------------------\n",
            " | 8 0 0 | 0 6 0 | 0 0 3 |\n",
            " | 4 0 0 | 8 0 3 | 0 0 1 |\n",
            " | 7 0 0 | 0 2 0 | 0 0 6 |\n",
            " -------------------------\n",
            " | 0 6 0 | 0 0 0 | 2 8 0 |\n",
            " | 0 0 0 | 4 1 9 | 0 0 5 |\n",
            " | 0 0 0 | 0 8 0 | 0 7 9 |\n",
            " -------------------------\n",
            "Answer: \n",
            " -------------------------\n",
            " | 5 3 4 | 6 7 8 | 9 1 2 |\n",
            " | 6 7 2 | 1 9 5 | 3 4 8 |\n",
            " | 1 9 8 | 3 4 2 | 5 6 7 |\n",
            " -------------------------\n",
            " | 8 5 9 | 7 6 1 | 4 2 3 |\n",
            " | 4 2 6 | 8 5 3 | 7 9 1 |\n",
            " | 7 1 3 | 9 2 4 | 8 5 6 |\n",
            " -------------------------\n",
            " | 9 6 1 | 5 3 7 | 2 8 4 |\n",
            " | 2 8 7 | 4 1 9 | 6 3 5 |\n",
            " | 3 4 5 | 2 8 6 | 1 7 9 |\n",
            " -------------------------\n",
            "Time used: 0.13515973091125488 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tJT4GBY90q_",
        "colab_type": "text"
      },
      "source": [
        "It can be noticed that the way an algorithm works is always the same for every sudoku puzzles. The algorithm will try to put some possible number into the blank box and backtrack if it reaches the invalid state. One programmer reported that such an algorithm may typically require as few as 15,000 cycles, or as many as 900,000 cycles to solve a Sudoku, each cycle being the change in position of a \"pointer\" as it moves through the cells of a Sudoku. Therefore, there are some sudoku puzzles that were especially created to work against the bracktracking program.\n",
        "<br>\n",
        "<br>A Sudoku can be constructed to work against backtracking. Assuming the solver works from top to bottom (as in the animation), a puzzle with few clues (17 initial numbers), no clues in the top row, and has a solution \"987654321\" for the first row, would work in opposition to the algorithm. Thus the program would spend significant time \"counting\" upward before it arrives at the grid which satisfies the puzzle. In one case, a programmer found a brute force program required six hours to arrive at the solution for such a Sudoku (albeit using a 2008-era computer). [1]\n",
        "<br>\n",
        "<br><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Sudoku_puzzle_hard_for_brute_force.svg/520px-Sudoku_puzzle_hard_for_brute_force.svg.png' width=250>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0455_yPQDDkf",
        "colab_type": "code",
        "outputId": "b65edb7d-3969-46b7-8dcb-8804dd4dcc5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "special_problem = [\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 3, 0, 8, 5],\n",
        "    [0, 0, 1, 0, 2, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 5, 0, 7, 0, 0, 0],\n",
        "    [0, 0, 4, 0, 0, 0, 1, 0, 0],\n",
        "    [0, 9, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [5, 0, 0, 0, 0, 0, 0, 7, 3],\n",
        "    [0, 0, 2, 0, 1, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 4, 0, 0, 0, 9]\n",
        "]\n",
        "\n",
        "print(\"Question Puzzle: \")\n",
        "print_sudoku(special_problem)\n",
        "print(\"Answer: \")\n",
        "start_time = time.time()\n",
        "print_sudoku(solve(special_problem))\n",
        "end_time = time.time()\n",
        "print(\"Time used:\",end_time - start_time,\"seconds\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question Puzzle: \n",
            " -------------------------\n",
            " | 0 0 0 | 0 0 0 | 0 0 0 |\n",
            " | 0 0 0 | 0 0 3 | 0 8 5 |\n",
            " | 0 0 1 | 0 2 0 | 0 0 0 |\n",
            " -------------------------\n",
            " | 0 0 0 | 5 0 7 | 0 0 0 |\n",
            " | 0 0 4 | 0 0 0 | 1 0 0 |\n",
            " | 0 9 0 | 0 0 0 | 0 0 0 |\n",
            " -------------------------\n",
            " | 5 0 0 | 0 0 0 | 0 7 3 |\n",
            " | 0 0 2 | 0 1 0 | 0 0 0 |\n",
            " | 0 0 0 | 0 4 0 | 0 0 9 |\n",
            " -------------------------\n",
            "Answer: \n",
            " -------------------------\n",
            " | 9 8 7 | 6 5 4 | 3 2 1 |\n",
            " | 2 4 6 | 1 7 3 | 9 8 5 |\n",
            " | 3 5 1 | 9 2 8 | 7 4 6 |\n",
            " -------------------------\n",
            " | 1 2 8 | 5 3 7 | 6 9 4 |\n",
            " | 6 3 4 | 8 9 2 | 1 5 7 |\n",
            " | 7 9 5 | 4 6 1 | 8 3 2 |\n",
            " -------------------------\n",
            " | 5 1 9 | 2 8 6 | 4 7 3 |\n",
            " | 4 7 2 | 3 1 9 | 5 6 8 |\n",
            " | 8 6 3 | 7 4 5 | 2 1 9 |\n",
            " -------------------------\n",
            "Time used: 2037.4108731746674 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNZgzVQAZggj",
        "colab_type": "text"
      },
      "source": [
        "You can see that this puzzle significantly used more time to solve than the normal puzzle (estimately 20374 times slower)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPqXqNvYiT51",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. Reinforcement Algorithm (Temporal Difference Control: Sarsa)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "To make an algorithm that the solving time does not depend on the puzzle itself, applying reinforcement learning techniques was thought to be the right solution. \n",
        "<br>\n",
        "<br>The idea was that an agent that can learn about how to reach final state of the sudoku puzzle in the fastest way, based on the given puzzle will be created. The agent will have general knowledge of the puzzle, that is, if the sudoku table still has at least a blank space, it will know which number should be filled in which blank space.\n",
        "<br>\n",
        "<br>To make this,  <b>TD-Control (Sarsa)</b> technique learned in the class was applied. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2euiLKi1Mxew",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3.1. State\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "TD-Control or Sarsa required the programmer to define 3 parameters; state, action, and reward. So, at the beginning, the problem of how the state of the sudoku puzzle should be defined was considered. The answer was that the entire table should be defined as a state. \n",
        "<br>\n",
        "<br>The agent needs to take an action (fill numbers) based on how the entire table looks like. This makes each number and its position hold some meanings and relations that can be used by the agent as a knowledge to guide itself to reach the terminal state. Therefore, all of that information in the state should be preserved. The state was then designed to be the entire sudoku table. In summary, the state for reinforcement learning is the 2D array that describes how the sudoku table look like.\n",
        "<br>\n",
        "<br><img src='data:image/png;base64,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' width=250> \n",
        "<br>\n",
        "<br>For an example, the state for sudoku above is the 2D list of<br>\n",
        "[<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[5, 3, 0, 0, 7, 0, 0, 0, 0],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[6, 0, 0, 1, 9, 5, 0, 0, 0],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[0, 9, 8, 0, 0, 0, 0, 6, 0],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[8, 0, 0, 0, 6, 0, 0, 0, 3],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[4, 0, 0, 8, 0, 3, 0, 0, 1],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[7, 0, 0, 0, 2, 0, 0, 0, 6],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[0, 6, 0, 0, 0, 0, 2, 8, 0],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[0, 0, 0, 4, 1, 9, 0, 0, 5],<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[0, 0, 0, 0, 8, 0, 0, 7, 9]<br>\n",
        "]<br> (As stated earlier, the blank space will be represented by 0.)\n",
        "<br>\n",
        "<br>For this case study, the start state is the given puzzle with some blank space, and the terminating state is the state that all spaces are filled with valid numbers (i.e. the puzzle is solved), or the state with some invalid numbers placed in the list (i.e. if algorithm tries to put some number to the blank space that makes the sudoku invalid, it will immediately terminate itself and start from starting point again).\n",
        "<br>\n",
        "<br>When an agent places some number on any blank position, the state will change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ps1OWcUO5Iv",
        "colab_type": "text"
      },
      "source": [
        "Here is the starting state we used in the case study. Please noted that, since the reinforcement learning can also take time and resources to train the agent to work properly, the size of sudoku is reduced from 9x9 to 4x4 so that the agent can faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtAhdRlqOytY",
        "colab_type": "code",
        "outputId": "e197ac68-4478-4a2b-a827-0be1c7d36acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Starting State\n",
        "question = [\n",
        "    [0,2,3,0],\n",
        "    [3,4,1,2],\n",
        "    [2,3,4,1],\n",
        "    [0,1,2,0]\n",
        "]\n",
        "print_sudoku(question)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " -------------\n",
            " | 0 2 | 3 0 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 0 1 | 2 0 |\n",
            " -------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLYmiKOcPQi6",
        "colab_type": "text"
      },
      "source": [
        "The function to check validity is needed to know whether the sudoku should terminate and start over or continue to the next step. Here is the code for that function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1TI4dL1PcHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_valid_row(container):\n",
        "  # Return True if every row in sudoku is valid\n",
        "  for row in container:\n",
        "    row = [x for x in row if x!= 0]\n",
        "    if len(row) != len(set(row)): \n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def is_valid_column(container):\n",
        "  # Return True if every column in sudoku is valid\n",
        "  containerLength = len(container)\n",
        "  for c in range(containerLength):\n",
        "    numbersInColumn = [number[c] for number in container if number[c] != 0]\n",
        "    if len(numbersInColumn) != len(set(numbersInColumn)):\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def is_valid_box(container):\n",
        "  # Return True if every small box in sudoku is valid\n",
        "  containerLength = len(container)\n",
        "  boxLength = int(math.sqrt(containerLength))\n",
        "  for r in range(0, containerLength, boxLength):\n",
        "    for c in range(0, containerLength, boxLength):\n",
        "      box = [b[c:c+boxLength] for b in container[r:r+boxLength]]\n",
        "      numbers = []\n",
        "      for row in box:\n",
        "        numbers.extend([x for x in row if x != 0])\n",
        "      if len(numbers) != len(set(numbers)):\n",
        "        return False\n",
        "  return True\n",
        "\n",
        "def is_valid(container):\n",
        "  # Return True if 3 conditions above is valid\n",
        "  if len(container) != len(container[0]):\n",
        "    print(\"Error: Sudoku container size is not valid\")\n",
        "    return False\n",
        "  rowStatus = is_valid_row(container)\n",
        "  columnStatus = is_valid_column(container)\n",
        "  boxStatus = is_valid_box(container)\n",
        "  return (rowStatus and columnStatus and boxStatus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyo04dZeSVKi",
        "colab_type": "text"
      },
      "source": [
        "The functions ***is_valid_row(container)***, ***is_valid_column(container)***, and ***is_valid_box(container)*** are used to check if the numbers in each row, column, and box are valid (i.e. no duplicated numbers) respectively. These are called by the function ***is_valid(container)***, which will return whether the puzzle is valid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcVQ66cLOe5h",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3.2. Action\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Actions for the agent in this case study is to select the blank space and fill a number from 1 to 9 in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce8MpxqXdzJE",
        "colab_type": "code",
        "outputId": "f6f6d391-3c1b-4b27-a010-2cc3007ab99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Starting State\n",
        "question = [\n",
        "    [0,2,3,0],\n",
        "    [3,4,1,2],\n",
        "    [2,3,4,1],\n",
        "    [0,1,2,0]\n",
        "]\n",
        "print_sudoku(question)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " -------------\n",
            " | 0 2 | 3 0 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 0 1 | 2 0 |\n",
            " -------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7CG89hRd0eL",
        "colab_type": "text"
      },
      "source": [
        "For example, the puzzle above have 4 blank spaces in the corner, each space can be place with number 1, 2, 3, or 4. Therefore, there are 4(blank spaces) * 4(possible numbers for each blank space) = 16 possible actions for this puzzle state.\n",
        "<br>\n",
        "<br>In this case study, the action was defined as a 3D tuple with these data:\n",
        "\n",
        "1.   Row of the selected blank space (r)\n",
        "2.   Column of the selected blank space (c)\n",
        "3.   Number that will place on the blank space (number)\n",
        "\n",
        "and is represented as (r, c, number).<br>\n",
        "<br>\n",
        "Here is the function for finding an action for each state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7plSKx0Qcgjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_action(state, blanks, epsilon):\n",
        "  numbers = [i+1 for i in range(len(state))]\n",
        "  \n",
        "  actions = []\n",
        "  for b in blanks:\n",
        "    for n in numbers:\n",
        "      actions.append((b[0], b[1], n))\n",
        "  \n",
        "  if not str(state) in Q:\n",
        "    Q.update({str(state):{}})\n",
        "    \n",
        "  possible_values = []\n",
        "  for a in actions:\n",
        "    if not a in Q[str(state)]:\n",
        "      Q[str(state)].update({a : 0})\n",
        "    possible_values.append(Q[str(state)][a])\n",
        "\n",
        "  if len(possible_values) == 0:\n",
        "    return 'terminate'\n",
        "  index_of_max = possible_values.index(max(possible_values))\n",
        "\n",
        "  probs = []\n",
        "  for i in range(len(actions)):\n",
        "    if i == index_of_max:\n",
        "      probs.append(1 - epsilon + (epsilon/len(actions)))\n",
        "    else:\n",
        "      probs.append(epsilon/len(actions))\n",
        "\n",
        "  actions = [str(a) for a in actions]\n",
        "  selected_action = random.choice(actions, p=probs)\n",
        "  \n",
        "  selected_action = selected_action[1:len(selected_action)-1]\n",
        "  selected_action = selected_action.split(', ')\n",
        "  selected_action = tuple(int(n) for n in selected_action)\n",
        "  \n",
        "  return selected_action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whd893zfVhbL",
        "colab_type": "text"
      },
      "source": [
        "The inputs are:\n",
        "\n",
        "\n",
        "*   **state** is the current state (i.e. the current filled sudoku table)\n",
        "*   **blanks** is a tuple (r, c), showing row and column of all blank space positoins\n",
        "*  **epsilon** is the epsilon value used for finding the current policy derived from Q\n",
        "\n",
        "<br>\n",
        "Please noted that Q matrix was defined as an empty dictionary at first and the values for each Q(state, action) will be initiated to be 0 whenever the new state is encountered. The structure of Q will be explained in the later section (3.3.4 Algorithm).<br>\n",
        "<br>\n",
        "\n",
        "For the variables in the function:\n",
        "\n",
        "*   **Q** is a global dictionary (will be explained later in section 3.3.4 Algorithm) representing the state-action values.\n",
        "*   **actions** is a list of 3D tuples of all possible actions for this state, consisting of (r, c, number), where r, c is the blank space position and number is the number to be filled.\n",
        "*   **possible_values** is a list of all state-action values of all possible actions. The length of **possible_values** is 0 if the state has no blank space left (i.e. reaches the terminating state).\n",
        "*   **index_of_max** is an index of an action in **possible_values** that has the maximum state-action value, which will be used to calculate the policy.\n",
        "*   **probs** is a list of all probabilities of all possible actions for this state.\n",
        "\n",
        "Noted that each action tuple is converted into string since the **numpy.random.choice()** only receives 1D list as an input. It will then be converted back as a tuple after finishing randoming the action.<br>\n",
        "<br>\n",
        "The function then returns the selected action as an output.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck5_TuPAe7B1",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3.3. Reward\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Since an agent uses rewards to improve the policy over time, here is how the reward for this case study was designed.\n",
        "- Each time agent takes an action, the reward equal to -1 is given back to the agent. \n",
        "- If the agent takes an action that makes the sudoku invalid, an additional -10 reward is added for that step.\n",
        "- If the agent takes an action that leads to the terminating state (i.e. can solve the puzzle), an additional reward of +20 is added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaOP1M-_foiX",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3.4. Algorithm\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Here is the main code for the Sarsa reinforcement learning technique for solving sudoku puzzle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8zSRa8DjOW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = {}\n",
        "\n",
        "def sarsa(state_original):\n",
        "  alpha = 0.5\n",
        "  gamma = 1\n",
        "  \n",
        "  for i in range(10000):\n",
        "    state = copy.deepcopy(state_original)\n",
        "    state_length = len(state)\n",
        "    blanks = [(r,c) for r in range(state_length) for c in range(state_length) if state[r][c] == 0]\n",
        "    epsilon = 1/(i+1)\n",
        "    \n",
        "    action = find_action(state, blanks, epsilon)\n",
        "    \n",
        "    \n",
        "    while '0' in str(state):\n",
        "      reward = -1\n",
        "      \n",
        "      next_state = copy.deepcopy(state)\n",
        "      next_state[action[0]][action[1]] = action[2]\n",
        "      \n",
        "      blanks.remove((action[0], action[1]))\n",
        "      next_action = find_action(next_state, blanks, epsilon)\n",
        "        \n",
        "      if not action in Q[str(state)]:\n",
        "        Q[str(state)].update({action : 0})\n",
        "      if not next_action in Q[str(next_state)]:\n",
        "        Q[str(next_state)].update({next_action : 0})\n",
        "        \n",
        "      if not is_valid(next_state):\n",
        "        reward -= 10\n",
        "        Q[str(state)][action] = Q[str(state)][action] + alpha*(reward + gamma*Q[str(next_state)][next_action] - Q[str(state)][action])\n",
        "        break\n",
        "        \n",
        "      if '0' not in str(next_state):\n",
        "        reward += 20\n",
        "        Q[str(next_state)][next_action] = 0\n",
        "      Q[str(state)][action] = Q[str(state)][action] + alpha*(reward + gamma*Q[str(next_state)][next_action] - Q[str(state)][action])\n",
        "      state = copy.deepcopy(next_state)\n",
        "      action = next_action\n",
        "      \n",
        "  return Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX6WoD2GgF7A",
        "colab_type": "text"
      },
      "source": [
        "The agent learns on the given puzzle for 10000 times to adjust the state-action values. The policy will then be derived from Q, the state-action values matrix.<br>\n",
        "<br>\n",
        "The structure chosen for Q is a dictionary since it will be easier to organize the code. The structure is in the form of:<br>\n",
        "{\n",
        "<br>&nbsp;&nbsp;state1:\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action1: value, \n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action2: value,\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ...\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},\n",
        "<br>&nbsp;&nbsp;state2:\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action1: value, \n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action2: value,\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ...\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}, \n",
        "<br>&nbsp;&nbsp;...\n",
        "<br>}\n",
        "<br>\n",
        "where **state1, state2,...** is each state of sudoku, and **action1, action2,...** are the possible actions for that state. An example of getting the state-action value of state ***s*** and action ***a*** is **Q[str(s)][a]**.<br>\n",
        "<br>\n",
        "Noted that the state is converted into string before being used as a pointer because the dictionary cannot use 2D or more data as a pointer.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9fZrc6AgAvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question = [\n",
        "    [0,2,3,0],\n",
        "    [3,4,1,2],\n",
        "    [2,3,4,1],\n",
        "    [0,1,2,0]\n",
        "]\n",
        "policy = sarsa(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqpxAy8GgZMU",
        "colab_type": "text"
      },
      "source": [
        "It can be seen that the policy is obtained for solving this sudoku, now the things left is to apply that policy to solve the puzzle. To do that, the print function is created to print base action from the given state in the policy. Here is the code for doing so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCkmqtOhjsOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_policy(state, q):\n",
        "  action_value = q[str(state)]\n",
        "  return max(action_value.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "def max_policy_describe(state, q):\n",
        "  action_value = q[str(state)]\n",
        "  solution = max(action_value.items(), key=operator.itemgetter(1))[0]\n",
        "  return \"Put number \" + str(solution[2]) + \" in position (\" + str(solution[0]) + \",\" + str(solution[1]) + \")\"\n",
        "\n",
        "def solve_sudoku_from_policy(container, policy):\n",
        "  output = copy.deepcopy(container)\n",
        "  print(\"From puzzle\")\n",
        "  print_sudoku(output)\n",
        "  next_action = max_policy(output, policy)\n",
        "  print(max_policy_describe(output, policy))\n",
        "  output[next_action[0]][next_action[1]] = next_action[2]\n",
        "  print_sudoku(output)\n",
        "  \n",
        "  while \"0\" in str(output):\n",
        "    next_action = max_policy(output, policy)\n",
        "    print(max_policy_describe(output, policy))\n",
        "    output[next_action[0]][next_action[1]] = next_action[2]\n",
        "    print_sudoku(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Cbo1L0g2Hy",
        "colab_type": "text"
      },
      "source": [
        "Then the function was used to find the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6YzC91WjjPw",
        "colab_type": "code",
        "outputId": "ec1d5b0e-b8ea-4aac-dee0-e9ff2b94be9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "start_time = time.time()\n",
        "solve_sudoku_from_policy(question, policy)\n",
        "end_time = time.time()\n",
        "print(\"Time used:\",end_time - start_time,\"seconds\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From puzzle\n",
            " -------------\n",
            " | 0 2 | 3 0 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 0 1 | 2 0 |\n",
            " -------------\n",
            "Put number 3 in position (3,3)\n",
            " -------------\n",
            " | 0 2 | 3 0 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 0 1 | 2 3 |\n",
            " -------------\n",
            "Put number 4 in position (3,0)\n",
            " -------------\n",
            " | 0 2 | 3 0 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Put number 1 in position (0,0)\n",
            " -------------\n",
            " | 1 2 | 3 0 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Put number 4 in position (0,3)\n",
            " -------------\n",
            " | 1 2 | 3 4 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Time used: 0.015764713287353516 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebgT2Pq7hOpG",
        "colab_type": "text"
      },
      "source": [
        "It can be noticed that with the policy from agent's knowledge, the puzzle can be solved in a very short time.\n",
        "<br>\n",
        "<br>From the above code, what is done is that the question puzzle state is found in the policy that the agent learned for a period of time. The policy for each state will tell the probability for each action in that state.<br>\n",
        "<br>\n",
        "Noted that the policy is obtained through deriving the values in the state-action values matrix, Q, using epsilon-greedy algorithm. Here is the state-action values of the first state obtained from the algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVuiQQWXIHc1",
        "colab_type": "code",
        "outputId": "8c4a7479-79f1-4285-ec5d-a867cc526576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "Q[str(question)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0, 1): -3.091155990958214,\n",
              " (0, 0, 2): -8.25,\n",
              " (0, 0, 3): -5.5,\n",
              " (0, 0, 4): -9.625,\n",
              " (0, 3, 1): -5.5,\n",
              " (0, 3, 2): -5.5,\n",
              " (0, 3, 3): -8.25,\n",
              " (0, 3, 4): -3.748046875,\n",
              " (3, 0, 1): -8.25,\n",
              " (3, 0, 2): -5.5,\n",
              " (3, 0, 3): -9.625,\n",
              " (3, 0, 4): -1.9479369819164276,\n",
              " (3, 3, 1): -5.5,\n",
              " (3, 3, 2): -9.625,\n",
              " (3, 3, 3): 16.0,\n",
              " (3, 3, 4): -8.25}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVgL_tROIMw1",
        "colab_type": "text"
      },
      "source": [
        "All the possible actions and the state-action values for this state can be seen from the output. The first two numbers in the tuple indicate the position of the blank space position. The third number is the number to be filled in that position. It can be represented as (r, c, number).<br>\n",
        "<br>\n",
        "Here, the maximum value is 16.0 from an action (3, 3, 3), which is considered the best action. The action (3, 3, 3) means to fill the number 3 into the blank space on the position (3, 3).\n",
        "<br>\n",
        "<br>After taking an action, the state will change to the next one. In this case, it is shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLmmjfx5IoHy",
        "colab_type": "code",
        "outputId": "e7ed0be9-6da9-4468-a7c7-bcf69a20a33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "question[3][3] = 3\n",
        "print_sudoku(question)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " -------------\n",
            " | 0 2 | 3 0 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 0 1 | 2 3 |\n",
            " -------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R92sJ946Ix_X",
        "colab_type": "text"
      },
      "source": [
        "Then the policy for this state was derived again and the new action was taken. This continued until the solution state was reached. That is how the algorithm works to find the solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjfzGg56IxR5",
        "colab_type": "code",
        "outputId": "541a8f07-d15e-4a81-e2e1-8c3a96dc2e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "Q[str(question)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0, 1): 5.4453125,\n",
              " (0, 0, 2): -5.5,\n",
              " (0, 0, 3): -5.5,\n",
              " (0, 0, 4): -5.5,\n",
              " (0, 3, 1): -5.5,\n",
              " (0, 3, 2): -5.5,\n",
              " (0, 3, 3): -8.25,\n",
              " (0, 3, 4): -0.96875,\n",
              " (3, 0, 1): -5.5,\n",
              " (3, 0, 2): -5.5,\n",
              " (3, 0, 3): -5.5,\n",
              " (3, 0, 4): 17.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV8CLUizJGf0",
        "colab_type": "text"
      },
      "source": [
        "In this case, the next action is to fill number 4 in the position (3, 0) since it has the highest value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Yepv1NxhgMJ",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3.5. Take a step further\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The next question is how to adapt this technique to work with any sudoku puzzle, not only the given puzzle used by the agent to learn for solving problem. Is it necessary to have an agent learned every sudoku in the world to make a policy that works with those puzzles? The answer is no. The agent can just learn to construct all possible sudoku from the all-zero puzzle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7GrcCuej7de",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allzero = [\n",
        "    [0,0,0,0],\n",
        "    [0,0,0,0],\n",
        "    [0,0,0,0],\n",
        "    [0,0,0,0]\n",
        "]\n",
        "policy_from_zero = sarsa(allzero)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoxeTxy7i8zJ",
        "colab_type": "text"
      },
      "source": [
        "This way, the agent will have much more wider knowledge about the possible output for many puzzles. The policy obtained can then be used to solve the puzzle, like in the previous question.\n",
        "<br>\n",
        "<br>For example, after the agent has learned by using an all-zero puzzle as a start state, its knowledge can be used to solve the new puzzle that the agent has never seen before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyAx7gQhmkP1",
        "colab_type": "code",
        "outputId": "a84e4455-6358-4d28-b998-3e2725798837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "new_question = [\n",
        "    [1,2,3,4],\n",
        "    [3,0,0,2],\n",
        "    [2,0,0,1],\n",
        "    [4,1,2,3]\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "solve_sudoku_from_policy(new_question, policy_from_zero)\n",
        "end_time = time.time()\n",
        "print(\"Time used:\",end_time - start_time,\"seconds\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From puzzle\n",
            " -------------\n",
            " | 1 2 | 3 4 |\n",
            " | 3 0 | 0 2 |\n",
            " -------------\n",
            " | 2 0 | 0 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Put number 4 in position (1,1)\n",
            " -------------\n",
            " | 1 2 | 3 4 |\n",
            " | 3 4 | 0 2 |\n",
            " -------------\n",
            " | 2 0 | 0 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Put number 4 in position (2,2)\n",
            " -------------\n",
            " | 1 2 | 3 4 |\n",
            " | 3 4 | 0 2 |\n",
            " -------------\n",
            " | 2 0 | 4 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Put number 3 in position (2,1)\n",
            " -------------\n",
            " | 1 2 | 3 4 |\n",
            " | 3 4 | 0 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Put number 1 in position (1,2)\n",
            " -------------\n",
            " | 1 2 | 3 4 |\n",
            " | 3 4 | 1 2 |\n",
            " -------------\n",
            " | 2 3 | 4 1 |\n",
            " | 4 1 | 2 3 |\n",
            " -------------\n",
            "Time used: 0.014703989028930664 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4KE8KN5y_t7",
        "colab_type": "text"
      },
      "source": [
        "This way, the reinforcement learning algorithm will work with any soduku puzzles exsiting with an amount of time used less than the brute force algorithm. \n",
        "<br>\n",
        "<br>The drawback of this method is only that it takes very long time to train an agent since it will try with a lot of possibilities and the memory will be needed to keep the state-action values for computing the policy. Furthermore, the higher *N* in *N x N* sudoku puzzle, the higher amount of time used for learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgYt0bpXzVmD",
        "colab_type": "text"
      },
      "source": [
        "## 4. 15-Puzzle Game\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnPndHTPJdU5",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. General Information about 15-Puzzle Game\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The 15-Puzzle is a good form of entertainment that has been popular for over 100 years. The puzzle is simple enough that it can be solved by children, but ones can have a difficult time solving it at first if they are not good at solving puzzles. The puzzle itself contains 16 box in form of 4x4 table. These boxes are filled with number 1 - 15 and leave one box empty. Numbers can be in any order possible. The aims of the game is simply to reorder the number 1-15 in the correct possition by moving/sliding the numbered boxes in up/down/left/right direction to switch place with the blank position until numbers are in an increasing order and the empty box is in the bottom right corner.<br>\n",
        "<br>\n",
        "The picture below shows an example of the 15-Puzzle problem. The left image is the problem given to the player and the right one is the desired state of the puzzle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xriJ4wbrNOw3",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"data:image/jpeg;base64,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\" width=250> <img src=\"https://rosettacode.org/mw/images/thumb/7/79/15_puzzle.png/300px-15_puzzle.png\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN5laHH8ue8Y",
        "colab_type": "text"
      },
      "source": [
        "Normally, the puzzle is usually in 4x4 matrix. However, it can be in the form of any *N x N* matrix, with the numbers from 1 to ($N^2- 1$) and one blank position. For an example, in 3x3 matrix, the number will be 1 to 8 with one blank position.<br>\n",
        "<br>\n",
        "In this case study, the 4x4 type will be used as a base type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x1rX42lOrjW",
        "colab_type": "text"
      },
      "source": [
        "### 4.2. Brute Force Algorithm\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "For this kind of puzzle, there is no explicit rule or way to solve it by following the instructor. What player mostly do is to try to arrange number one by one into the correct position. For example, player will try to place number 1 first in the top left corner. Then try to place number 2 next to the number 1. This will go on and on until the player finishes placing number 15. Along the way, some corrected position number will also have to move in order to make the other numbers possible to move. Therefore, there is an algorithm that can explicitly solve the 15-puzzle game, which is to do the brute force with the search tree. \n",
        "<br>\n",
        "<br>Since, for 15 puzzle, there are (15+1)!/2 = 10,461,394,944,000 possible states and finding the shortest possible solution to any given N-Puzzle has been proven to be NP-complete, the brute-force technique must be informed in order to solve puzzle.\n",
        "<br>\n",
        "<br>Algorithm for doing brute force 15-puzzle will not be shown here since the algorithm is very long. We recommend to check [N-puzzle solver from jgardner8's GitHub](https://github.com/jgardner8/NPuzzle) for more information about how to use brute force with 15-puzzle problem. [2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzOXLPLGRRuQ",
        "colab_type": "text"
      },
      "source": [
        "### 4.3. Reinforcement Algorithm (Temporal Difference Control: Sarsa)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Like sudoku game, using reinforcement learning techques with 15-puzzle was believed to be more suitable and use less amount of time to solve the puzzle. Therefore, the idea is to use TD control (Sarsa) technique with the 15-puzzle game.\n",
        "<br>\n",
        "<br>To do that, the state, actions, and rewards for this puzzle are defined."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4mfbPuLR9pv",
        "colab_type": "text"
      },
      "source": [
        "#### 4.3.1. State\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Same as the sudoku puzzle, the entire number position in 15-puzzle table have their meanings and relations. Therefore, to define a state for this puzzle game, the whole table was used (same as in Sudoku).\n",
        "This time, the numpy array was used as a structure instead of the list. The state was defined as a 2D numpy array where each index contains number 0 to 15 and represents the position of that number (again, 0 represents the blank position).\n",
        "<br>\n",
        "<br><img src=\"https://cdncontribute.geeksforgeeks.org/wp-content/uploads/15-puzzle.png\" width=200> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAPoGzekjEGL",
        "colab_type": "text"
      },
      "source": [
        "For an example, the above initial 15-puzzle can be represent in the state as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "168hOd14jKoW",
        "colab_type": "code",
        "outputId": "93e15015-dfab-4df8-9e97-e6df0da16f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "board = [\n",
        "    [ 2,  1,  3,  4],\n",
        "    [ 5,  6,  7,  8],\n",
        "    [ 9, 10, 11, 12],\n",
        "    [13, 14, 15,  0]\n",
        "]\n",
        "board = np.array(board)\n",
        "print(board)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  1  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]\n",
            " [13 14 15  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3APBjLjjpTV",
        "colab_type": "text"
      },
      "source": [
        "For the start state, it can be any 4x4 table fill with number 1-15 and leave one position blank. However, to guarantee that the puzzle can be solve, some rules are needed.\n",
        "<br>\n",
        "<br>For a given grid of $N x N$:\n",
        "- If N is odd, then puzzle instance is solvable if number of inversions is even in the input state.\n",
        "- If N is even, puzzle instance is solvable if:\n",
        "    - the blank is on an even row counting from the bottom (second-last, fourth-last, etc.) and the number of inversions is odd.\n",
        "    - the blank is on an odd row counting from the bottom (last, third-last, fifth-last, etc.) and the number of inversions is even.\n",
        "- For all other cases, the puzzle instance is not solvable. [3]\n",
        " \n",
        "<br>\n",
        "where the number of inversions will be describe as follows.\n",
        "<br>\n",
        "Assuming the tiles written out in a single row (1D Array) instead of being spread in $N$rows and $N$ column (2D Array), the number of inversions is the number of pairs of tiles $(a, b)$ that $a$ appears before $b$ and $a > b$ where $a$ and $b$ are the number from 1 to 15 (meaning that the blank position is excluded).<br>\n",
        "<br>\n",
        "For an above example, consider the tiles written out in a single row:\n",
        "<br><b>2 1 3 4 5 6 7 8 9 10 11 12 13 14 15 0</b>\n",
        "<br>The above grid forms only 1 inversion i.e. (2, 1). [3]\n",
        "<br>\n",
        "<br>Here is another example to see how to check whether the puzzle is solvable.\n",
        "<br><img src=\"https://www.geeksforgeeks.org/wp-content/uploads/15Puzz3.png\" width=250><img src=\"https://www.geeksforgeeks.org/wp-content/uploads/15Puzz4.png\" width=250>\n",
        "<br>\n",
        "<br>Therefore, to check if the puzzle is solvable or not, the function was created. Here is the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnjJSbYNl7VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_inversion_count(board):\n",
        "  # Return the number of incersion\n",
        "  flattened_board = board.flatten()\n",
        "  inversion_count = 0\n",
        "  \n",
        "  for i in range(len(flattened_board)):\n",
        "    if flattened_board[i] == 0:\n",
        "      continue\n",
        "    for j in range(i+1,len(flattened_board)):\n",
        "      if flattened_board[j] == 0:\n",
        "        continue\n",
        "      if flattened_board[i] > flattened_board[j]:\n",
        "        inversion_count += 1\n",
        "\n",
        "  return inversion_count  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCfE7QTgVJlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_blank_index(board):\n",
        "  # Return the blank box index from the state\n",
        "  return np.where(board == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOQ3HpHalRG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_solvable(board):\n",
        "  # Return True if puzzle is solvable\n",
        "  rows_count = len(board)\n",
        "  columns_count = len(board[0])\n",
        "\n",
        "  for row in board:\n",
        "    if len(row) != columns_count:\n",
        "      print(\"Invalid board. Each row needs to have the same length.\")\n",
        "      return False\n",
        "\n",
        "  if rows_count != columns_count:\n",
        "    print(\"Invalid board. The dimension has to be N*N.\")\n",
        "    return False\n",
        "\n",
        "  all_numbers = [i+1 for i in range(rows_count*columns_count-1)]\n",
        "  for row in board:\n",
        "    for item in row:\n",
        "      if item == 0:\n",
        "        continue\n",
        "      if item in all_numbers:\n",
        "        all_numbers.remove(item)\n",
        "      else:\n",
        "        print('Invalid board. Duplicated number detected.')\n",
        "        return False\n",
        "\n",
        "  blank_index = find_blank_index(board)\n",
        "  if blank_index[0].size <= 0:\n",
        "    print('Invalid board. No blank found.')\n",
        "    return False\n",
        "  elif blank_index[0].size > 1:\n",
        "    print('Invalid board. More than one blank detected.')\n",
        "\n",
        "  inversion_count = find_inversion_count(board)\n",
        "  blank_row_position = blank_index[0]\n",
        "  if rows_count % 2 == 0:\n",
        "    if blank_row_position % 2 == 0 and inversion_count % 2 != 0:\n",
        "      return True\n",
        "    elif blank_row_position % 2 != 0 and inversion_count % 2 == 0:\n",
        "      return True\n",
        "  else:\n",
        "    if inversion_count % 2 == 0:\n",
        "      return True\n",
        "\n",
        "  print('The board is unsolvable')\n",
        "  return False   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlKBD6tJl9gd",
        "colab_type": "text"
      },
      "source": [
        "The function ***find_inversion_count(board)*** is called by the ***is_solvable(board)*** function to find the number of inversions. The **flatten()** from numpy helps to flatten the board from 2D to 1D, which makes it easier to find the inversions. This is one reason for using the numpy array instead of a normal list.<br>\n",
        "<br>\n",
        "The general concept of finding inversions is that two loops are used. The outer loop marks the position of one number. The inner will then repeatedly find all numbers that come after this marked number. If the number in the inner loop is lower than the one from the outer loop, the inversions count increases. Noted that the number 0 is excluded since it represents the blank position.<br>\n",
        "<br>\n",
        "The function ***find_blank_index(board)*** is used to find the index of the blank position. This function is just a simple single-row function which calls numpy array but the purpose is for the better readable code. It is called by the ***is_solvable(board)*** to find the position and check whether it is on the odd or even row. It will also be called later when using the algorithm to solve the puzzle.<br>\n",
        "<br>\n",
        "The function ***is_solvable(board)*** is the main function which returns whether the board is solvable. It also checks cases of a wrong input. The type of wrong input can be noticed by the print function in each condition.<br>\n",
        "<br>\n",
        "Then the function to create the terminal state for any N-puzzle game was created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVl5WMYlU4Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_terminating(N):\n",
        "  terminate = []\n",
        "  for r in range(N):\n",
        "    terminate.append([])\n",
        "    for c in range(N):\n",
        "      terminate[r].append(N*r+c+1)\n",
        "\n",
        "  terminate[r][c] = 0\n",
        "  return np.array(terminate)\n",
        "\n",
        "TERMINATING = init_terminating(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE3MAs3WU9zY",
        "colab_type": "code",
        "outputId": "b668e466-cda1-4924-9932-8b8390c935a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(TERMINATING)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]\n",
            " [13 14 15  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfKMMjCD21cS",
        "colab_type": "text"
      },
      "source": [
        "For 15-puzzle, there is only one terminal state, the state where numbers are ordered from 1 to 15 and leave the buttom right corner blank. It can be represented as a numpy array shown above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFiK5auvoXn6",
        "colab_type": "text"
      },
      "source": [
        "The helper function to find the next state from the current state and actionwas also created. Here is the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6MOykPWoX3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_next_state(input_state, action):\n",
        "  state = copy.deepcopy(input_state)\n",
        "  blank_position = find_blank_index(state)\n",
        "  row = blank_position[0]\n",
        "  column = blank_position[1]\n",
        "  \n",
        "  if action == ACTIONS[0]:\n",
        "    state[row, column], state[row-1, column] = state[row-1, column], state[row, column]\n",
        "  elif action == ACTIONS[1]:\n",
        "    state[row, column], state[row+1, column] = state[row+1, column], state[row, column]\n",
        "  elif action == ACTIONS[2]:\n",
        "    state[row, column], state[row, column-1] = state[row, column-1], state[row, column]\n",
        "  elif action == ACTIONS[3]:\n",
        "    state[row, column], state[row, column+1] = state[row, column+1], state[row, column]\n",
        "    \n",
        "  return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjI8s3E83COW",
        "colab_type": "text"
      },
      "source": [
        "The function just checks the action taken and swap the position of the blank position with the state above/below/to the left of/to the right of the blank based on the action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMU1bGLzSBIN",
        "colab_type": "text"
      },
      "source": [
        "#### 4.3.2. Action\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "For actions in 15-puzzle, there are maximum of 4 actions possible; move the blank box up, down, left, or right. Therefore, the arrows were used to represent these actions as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2JNCip3U6Vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ACTIONS = ['↑','↓','←','→']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tpd53RjnjOm",
        "colab_type": "text"
      },
      "source": [
        "A function was created to find the next action. Here is the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skaw0WLDVWtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_action(state, epsilon):\n",
        "  # Return action to take\n",
        "  global Q\n",
        "  blank_position = find_blank_index(state)\n",
        "  board_size = len(state)\n",
        "\n",
        "  row = blank_position[0]\n",
        "  column = blank_position[1]\n",
        "  possible_actions = copy.deepcopy(ACTIONS)\n",
        "  if row == 0:\n",
        "    possible_actions.remove(ACTIONS[0])\n",
        "  elif row == board_size - 1:\n",
        "    possible_actions.remove(ACTIONS[1])\n",
        "  if column == 0:\n",
        "    possible_actions.remove(ACTIONS[2])\n",
        "  elif column == board_size - 1:\n",
        "    possible_actions.remove(ACTIONS[3])\n",
        "\n",
        "  if str(state) not in Q:\n",
        "    Q.update({str(state):{}})\n",
        "    \n",
        "  possible_action_values = []\n",
        "  for a in possible_actions:\n",
        "    if a not in Q[str(state)]:\n",
        "      Q[str(state)].update({a : 0})\n",
        "    possible_action_values.append(Q[str(state)][a])\n",
        "  \n",
        "  best_action_index = possible_action_values.index(max(possible_action_values))\n",
        "  probs = []\n",
        "  for i in range(len(possible_actions)):\n",
        "    if i == best_action_index:\n",
        "      probs.append(1 - epsilon + (epsilon/len(possible_actions)))\n",
        "    else:\n",
        "      probs.append(epsilon/len(possible_actions))\n",
        "      \n",
        "  selected_action = random.choice(possible_actions, p=probs)\n",
        "  \n",
        "  return selected_action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdu95dv36FR3",
        "colab_type": "text"
      },
      "source": [
        "The ***find_action(state, epsilon)*** function receives two input - state and epsilon. The general concept is that all actions are added in to the list **possible_actions**. Each element in **possible_actions** is just a string of one arrow. Then it checks whether the blank position is next to the border and removes the impossible actions. For an example, if the blank position is on the bottom row (last row), the action of going down is removed. The **possible_actions** list now contains only possible actions as its name says.<br>\n",
        "<br>\n",
        "Noted that Q matrix or the state-action values matrix works the same way as was done in Sudoku. It was defined as an empty dictionary at first and the values for each Q(state, action) will be initiated to be 0 whenever the new state is encountered. The structure of Q will be explained in the later section (4.3.4 Algorithm).<br>\n",
        "<br>\n",
        "The epsilon-greedy algorithm is then used to find the policy or the probabilities of actions for choosing the action.<br>\n",
        "<br>\n",
        "The function finally returns the selected action as an output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH1TlY9ZSEPK",
        "colab_type": "text"
      },
      "source": [
        "#### 4.3.3. Reward\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Since an agent uses rewards to improve the policy over time, here is how the reward for this 15-puzzle game algorithm was designed.\n",
        "- Each time the agent takes an action, the reward equal to -1 is given back to the agent. \n",
        "- If the agent can take an action that leads to the terminate state (i.e. the puzzle is solved), an additional reward +30 is added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzpSwXuJSII4",
        "colab_type": "text"
      },
      "source": [
        "#### 4.3.4. Algorithm\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Here is the main code for the Sarsa reinforcement learning technique for solving 15-puzzle.\n",
        "<br>\n",
        "<br>Noted that the agent was limited to be able to take actions for only 100 times. If it reaches that number and agent still cannot find the terminating state, it will immediately end that loop and start over from the beginning again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKrZ2SSjVdns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = {}\n",
        "\n",
        "def sarsa(board):\n",
        "  alpha = 0.5\n",
        "  gamma = 0.3\n",
        "  for i in range(10000):\n",
        "    state = copy.deepcopy(board)\n",
        "    epsilon = 1/(i+1)\n",
        "\n",
        "    action = find_action(state, epsilon)\n",
        "    j = 0\n",
        "    reward = 0\n",
        "    while j < 100 and not np.array_equal(state, TERMINATING):\n",
        "      j+=1\n",
        "      reward -= 1\n",
        "      next_state = find_next_state(state, action)\n",
        "      next_action = find_action(next_state, epsilon)\n",
        "\n",
        "      if np.array_equal(next_state, TERMINATING):\n",
        "        reward += 30\n",
        "      if action not in Q[str(state)]:\n",
        "        Q[str(state)].update({action : 0})\n",
        "      Q[str(state)][action] += alpha*(reward + gamma*Q[str(next_state)][next_action] - Q[str(state)][action])\n",
        "      state = copy.deepcopy(next_state)\n",
        "      action = next_action\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O_XjJiHVgZM",
        "colab_type": "text"
      },
      "source": [
        "The agent learned from the given puzzle for 10000 times to adjust the state-action values, which were stored in Q. The policy will then be derived from Q.<br>\n",
        "<br>\n",
        "The structure chosen for Q is a dictionary since it will be easier to organize the code (same as in Sudoku). The structure is in the form of:<br>\n",
        "{\n",
        "<br>&nbsp;&nbsp;state1:\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action1: value, \n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action2: value,\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ...\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},\n",
        "<br>&nbsp;&nbsp;state2:\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action1: value, \n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; action2: value,\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ...\n",
        "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}, \n",
        "<br>&nbsp;&nbsp;...\n",
        "<br>}\n",
        "<br>\n",
        "where **state1, state2,...** are states of the 15_puzzle and **action1, action2,...** are possible actions for that state, which are each a string of single arrow ('↑','↓','←','→'). An example of getting the state-action value of state ***s*** and action ***a*** is **Q[str(s)][a]**<br>\n",
        "<br>\n",
        "Noted that the state is converted in to string for the same purpose as in Sudoku (dictionary cannot use many dimensional object as a pointer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaXjMXW5UpKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "board = [\n",
        "    [ 1,  2,  3,  4],\n",
        "    [ 5,  6,  7,  8],\n",
        "    [ 9, 10, 11,  0],\n",
        "    [13, 14, 15, 12]\n",
        "        ]\n",
        "board = np.array(board)\n",
        "if is_solvable(board):\n",
        "  sarsa(board)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPpY7a2jVj_7",
        "colab_type": "text"
      },
      "source": [
        "Now that the matrix Q is obtained, the policy can be derived. Here is an example of the state-action values of the initial board."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3zvrRJYVrSE",
        "colab_type": "code",
        "outputId": "9b707e11-e8ee-4fc9-9ecb-66848cbf1eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(Q[str(board)])\n",
        "print(\"Maximum Probability: \",max(Q[str(board)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'↑': -1.025, '↓': 29.0, '←': -0.3879605376720429}\n",
            "Maximum Probability:  ↓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkuQ6HFBYdCz",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the maximum value is from an action of moving the blank downward. Therefore, the next action chosen is to move the box at that direction. The process is repeated until the terminating state is reached.\n",
        "<br>\n",
        "<br>To make it simpler to understand, the print function was created to print out the entire solution for the puzzle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0y2xt_DWrg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_policy(state, q):\n",
        "  action_value = q[str(state)]\n",
        "  return max(action_value.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "def max_policy_describe(state, q):\n",
        "  action_value = q[str(state)]\n",
        "  solution = max(action_value.items(), key=operator.itemgetter(1))[0]\n",
        "  return \"Move the blank box in \" + str(solution) + \" direction.\"\n",
        "\n",
        "def solve_15puzzle_from_policy(container, policy):\n",
        "  output = copy.deepcopy(container)\n",
        "  print(\"From puzzle\")\n",
        "  print(output)\n",
        "  next_action = max_policy(output, policy)\n",
        "  print(max_policy_describe(output, policy))\n",
        "  output = find_next_state(output,next_action)\n",
        "  print(output)\n",
        "  \n",
        "  while not np.array_equal(output,TERMINATING):\n",
        "    next_action = max_policy(output, policy)\n",
        "    print(max_policy_describe(output, policy))\n",
        "    output = find_next_state(output,next_action)\n",
        "    print(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjXn5K_YYJqe",
        "colab_type": "code",
        "outputId": "247cc9b2-3c87-4942-b563-68df29dc98a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "solve_15puzzle_from_policy(board,Q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From puzzle\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11  0]\n",
            " [13 14 15 12]]\n",
            "Move the blank box in ↓ direction.\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]\n",
            " [13 14 15  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163nBzWkCqxs",
        "colab_type": "text"
      },
      "source": [
        "The function will print all actions that should be taken until it reaches the terminating state. In this case, it needs only one action in order to reach the terminating state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5ADTiunJgSl",
        "colab_type": "text"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Throughout this case study, it can be said that the reinforcement learning is absolutely a great technique to implement in solving the task that normally takes time to process with brute force algorithm. The difference between these two algorithms is that brute force, as its name says, uses only its brute strength to find the solution (just try all possible cases) while reinforcement learning uses the concept of knowledge and experiences in order to solve the problem, which is very helpful in the domain of puzzle games, where having general knowledge about the game will help the player solve that puzzle faster.\n",
        "<br>\n",
        "<br>First, an experiment of implementing the reinforcement learning into sudoku puzzle was done. The outcome was the agent that can solve any 4x4 sudoku puzzle in less than a minute. Unlike brute force algorithm that some Sudoku problems can be constructed to prevent, the reinforcement learning algorithm can solve problems very fast with independence of how the initial problem look like. That is because of the agent has already tried that sudoku again and agian to find the optimal solution to solve the problem. Therefore, if the output has already been found, it can generate the output within a few seconds.\n",
        "<br>\n",
        "<br>Also, in the 15-puzzle game, the agent was built to learn the puzzle and the policy was made from the state-action calues to solve the problem. After letting the agent learn for some period of time, it can solve any puzzle of this game within minutes, which is very fast compared to the brute firce algorithm.\n",
        "<br>\n",
        "<br>However, one major problem were encountered during this case study. To build the accurate and high performance agents, a lot of time and resources are needed. For example, to train an agent to work with 9x9 sudoku from an all-zero table, it will take more than a couple of days to gain general knowledge used to solve some basic sudoku puzzles (only 3 or 4 blank space), and is still not possible to solve all Sudoku problems. That is why in this case study, only 4x4 sudoku was usedas the experiment puzzle. The same goes for the 15-puzzle game, the agent was trained for a couple of hours and can only solve one or two basic problems that take less than 3 steps to solve the puzzle.\n",
        "<br>\n",
        "<br>Some other problems encountered were about start and terminating states for Sudoku. Each start state of Sudoku has their own terminating state (solved state). Since there are many possible start states. there are also many terminating states. This was quite a problem since reinforcement learning algorithm that was built only depended on one terminating state. The agent will need to train entirely again if the start state changes since most of Sudoku problems have different sets of possible states. For the trick used in this case study, the agent was set to learn from an all-zero table so that it will have more knowledge about the states without having to train from each possible state in the puzzle agian. Using this way to train agent for a long time will guarantee that the agent will know most of the puzzles and be able to solve them properly.<br>\n",
        "<br>\n",
        "As for the 15-puzzle game, the problem of various possible states does not matter since they all have the same terminating state. However, the actual problem, that was also encountered, could be the very low chance of reaching the only one terminating state. The ratio of the terminating state over all possible states is very little. In this case study, the number of steps needed to do until reaching terminating state from the 15-puzzle problem is only one step. However, if this number increases, for an example, to 10 steps, the agent will not be able to find the terminating state since within these 10 steps, there are many possible states that can be reached and at earlier trial, the agent just randomly moves the tiles with no knowledge. As a result, the agent will reach the action steps limit and start over again. The chance to reach the terminating state is dramatically low.<br>\n",
        "<br>\n",
        "This might lead to the question \"Why don't we give more time to the agent by removing the action steps limit?\". Actually, at first, there was no limit. The result was that the agent could not even finish one episode (i.e. could not reach the terminating state). It was because at first, the agent had no knowledge and moved randomly. With that randomness, it caused the agent to diverge from the terminating state. Therefore, the limit were set with an idea of if the agent moves over 100 times, that path is considered a bad path, so it should stop going to the bad path and start finding the correct path from the beginning again.<br>\n",
        "<br>\n",
        "The optimal method has not been found yet. The program may have to be more complicated but that could be experimented after we have gained more knowledge about reinforcement learning.<br>\n",
        "<br>\n",
        "In conclusion, we think that the reinforcement learning is absolutely helpful in domain of gaming and puzzle since these problem usually required knowledge of player to solve the game. I would like to use the word from István Szita's Reinforcement Learning in Games to conclude that \"...without any modifications, the basic reinforcement learning algorithms are rarely sufficient for high-level gameplay, so it is essential to discuss the additional ideas, ways of inserting domain knowledge, implementation decisions that are necessary for scaling up\". [4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWsl1r8CxIvM",
        "colab_type": "text"
      },
      "source": [
        "## 6. References\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "[1] Sudoku Solving Algorithm. (Retrieved from https://en.wikipedia.org/wiki/Sudoku_solving_algorithms on May 5, 2019)\n",
        "<br>[2] N-puzzle Brute Force Solver (Retrieved from https://github.com/jgardner8/NPuzzle on May 6, 2019)\n",
        "<br>[3] How to check if an instance of 15 puzzle is solvable? (Retrieved from https://www.geeksforgeeks.org/check-instance-15-puzzle-solvable/ on May 6, 2019)\n",
        "<br>[4] István Szita: Reinforcement Learning in Games (2012)"
      ]
    }
  ]
}